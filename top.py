from nltk.tokenize import word_tokenize as wt

# Example usage:
text = "Hello, how are you?"
tokens = wt(text)
print(tokens)